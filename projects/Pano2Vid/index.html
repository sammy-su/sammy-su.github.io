<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
        <title>Pano2Vid</title>

        <!-- Bootstrap -->
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/custom.css" type="text/css" rel="stylesheet">

        <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
            <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->
    </head>

    <body>

        <div class="container">
            <nav class="navbar navbar-default navbar-static-top">
                <div class="container-fluid">
                    <div class="navbar-header">
                        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
                            <span class="sr-only">Toggle navigation</span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </button>
                        <a class="navbar-brand" href="../../publications.html">
                            <span class="glyphicon glyphicon-home" aria-hidden="true"></span>
                        </a>
                    </div>

                    <div id="navbar" class="navbar-collapse collapse">
                        <ul class="nav navbar-nav">
                            <li><a href="#motivation">Motivation</a></li>
                            <li><a href="#Pano2Vid">Pano2Vid</a></li>
                            <li><a href="#AutoCam">AutoCam</a></li>
                            <li><a href="#Experiment">Experiment</a></li>
                            <li><a href="#Video">Video</a></li>
                            <li><a href="#publication">Publication</a></li>
                        </ul>
                    </div><!--/.nav-collapse -->
                </div>
            </nav>

            <div class="row">
                <div class="row">
                    <h1><p class="text-center">Pano2Vid: Automatic Cinematography for Watching 360° Videos</p></h1>
                </div>
                <div class="row">
                    <img src="figures/concept.png" class="img-responsive center-block" alt="Concept figure" style="max-width:96%; width:720px;">
                </div>
                <p style="font-size:18px; margin-top:18px">
                A 360° camera captures the entire visual world from its optical center,
                which provides exciting new ways to record and experience visual content by relieving restrictions on the field-of-view (FOV).
                Videographers no longer have to determine what to capture in the scene,
                and human viewers can freely explore the visual content.
                On the other hand, it also introduces new challenges for the video viewer.
                The video viewer has to decide “where and what” to look at by controlling the viewing direction throughout the full duration of the video.
                Because the viewer has no information about the content beyond the current FOV,
                it may be difficult to find interesting content and determine where to look in real time.
                </p>
                <p style="font-size:18px; margin-top:18px">
                To address this difficulty, we define “Pano2Vid”, a new computer vision problem.
                The task is to design an algorithm that automatically controls the pose and motion of a virtual normal-field-of-view (NFOV) camera within an input 360° video.
                Camera control must be optimized to produce video that could conceivably have been captured by a human observer equipped with a real NFOV camera.
                A successful Pano2Vid solution would therefore take the burden of choosing “where to look” off both the videographer and the end viewer:
                the videographer could enjoy the moment without consciously directing her camera,
                while the end viewer could watch intelligently-chosen portions of the video in the familiar NFOV format.
                </p>
                [<a href="#">top</a>]
            </div>

            <div class="row" id="motivation">
                <h2>Motivation</h2>
                <hr class="single">
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/6dtlnp56v5hhjhb/motivation.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
                <p style="font-size:18px; margin-top:18px">
                    When watching 360° videos, the human viewer needs to actively control the viewing direction.
                    This is not a trivial task, because the viewer has no information beyond the current field of view.
                    For example, in the above video, the viewer fails to notice that there is an elephant approaching the camera from the opposite direction at the beginning.
                    Therefore, the key challenge for watching 360° video is how to find the right direction to watch.
                </p>
                [<a href="#">top</a>]
            </div>

            <div class="row" id="Pano2Vid">
                <h2>The Pano2Vid Problem</h2>
                <hr class="single">
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/st793g1c87516hn/pano2vid_problem.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
                <p style="font-size:18px; margin-top:18px">
                    To overcome the challenge of viewing 360° video, we propose a new computer vision problem that helps people determine where and what to look at in 360° video.
                </p>
                <ul style="font-size:18px; margin-top:18px">
                    <li>Input: 360° video</li>
                    <li>Output: normal-field-of-view video</li>
                    <li>Task: controls the virtual camera direction (in 2D spherical direction)</li>
                    <li>Goal: generate videos look as if captured by human videographer in the scene</li>
                </ul>
                [<a href="#">top</a>]
            </div>

            <div class="row" id="AutoCam">
                <h2>AutoCam</h2>
                <hr class="single">
                <h3>Spatio-temporal Glimpse</h3>
                <div class="row">
                    <img src="figures/st_glimpse.png" class="img-responsive center-block" alt="Spatio-temporal Glimpse" style="max-width:96%; width:720px;">
                </div>
                <p style="font-size:18px; margin-top:18px">
                    A spatio-temporal glimpse is a short normal-field-of-view video extracted from 360° video with fixed viewing direction.
                    It transforms 360° content into normal video and makes the visual feature comparable.
                </p>
                <h3>Capture-worthiness</h3>
                <div class="row">
                    <img src="figures/capture_worthiness.png" class="img-responsive center-block" alt="Capture-worthiness" style="max-width:96%; width:720px;">
                </div>
                <p style="font-size:18px; margin-top:18px">
                    We define capture-worthiness as how much a spatio-temporal glimpse looks like human-captured normal-field-of-view videos ("HumanCam").
                </p>
                <h3>Sample Spatio-temporal Glimpse</h3>
                <div class="row">
                    <img src="figures/sample_glimpses.png" class="img-responsive center-block" alt="Sample ST-glimpses" style="max-width:96%; width:720px;">
                </div>
                <p style="font-size:18px; margin-top:18px">
                    Given a 360° video, we densely sample spatio-temporal glimpses both spatially and temporally.
                    We sample 198 glimpses at 18 azimutal angles and 11 polar angles every 5 seconds.
                    We then estimate the capture-worthiness score for all the glimpses.
                </p>
                <h3>Construct Virtual Camera Trajectory</h3>
                <div class="row">
                    <img src="figures/construct_trajectory.png" class="img-responsive center-block" alt="Construct trajectories" style="max-width:80%; width:480px;">
                </div>
                <p style="font-size:18px; margin-top:18px">
                    We transform the problem of controlling viewing direction into selecting one spatio-temporal glimpse each moment in the video.
                    We find a path over the spatio-temporal glimpses that maximize the accumulated capture-worthiness score while obeying a smooth camera motion constraint,
                    which forbids the virtual camera from performing abrupt motion.
                    The problem can be reduced to a shortest path problem and solved by dynamic programming.
                </p>
                [<a href="#">top</a>]
            </div>

            <div class="row" id="Experiment">
                <h2>Experiment</h2>
                <hr class="single">
                <h3>Dataset</h3>
                <p style="font-size:18px; margin-top:18px">
                    We collect the 360° and HumanCam videos from YouTube using following keywords: <em>"Hiking", "Mountain Climbing", "Parade", "Soccer"</em>.
                </p>
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <table class="table" style="font-size: 18px">
                            <thead>
                                <tr>
                                    <th></th>
                                    <th># Videos</th>
                                    <th>Total Length</th>
                                </tr>
                            </thead>
                            <tbody>
                            <tr>
                                <td>360° Videos</td>
                                <td>86</td>
                                <td>7.3 hours</td>
                            </tr>
                            <tr>
                                <td>HumanCam</td>
                                <td>9,171</td>
                                <td>343 hours</td>
                            </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
                <h3>Baselines</h3>
                <div class="row">
                    <!--div class="col-md-3 col-md-offset-2">
                        <img src="figures/center_prior.png" class="img-responsive center-block" alt="Center Prior" style="width:240px; max-width=72%">
                    </div>
                    <div class="col-md-3">
                        <img src="figures/eyelevel_prior.png" class="img-responsive center-block" alt="Eye-level Prior" style="width:240px; max-width=72%">
                    </div>
                    <div class="col-md-3">
                        <img src="figures/saliency_baseline.png" class="img-responsive center-block" alt="Saliency" style="width:240px; max-width=72%">
                    </div--!>
                    <ul style="font-size:18px">
                        <li>Center prior &ndash; random trajectories biased toward center in 360° camera axis</li>
                        <li>Eye-level prior &ndash; static trajectories lying on the equator</li>
                        <li>Saliency &ndash; replace capture-worthiness score with saliency score in AutoCam</li>
                    </ul>
                </div>
                <h3>Evaluation Metrics</h3>
                <div class="row">
                    <ul style="font-size:18px">
                        <li>HumanCam-based Metrics &ndash; whether the algorithm generated videos look like HumanCam videos</li>
                        <ul style="font-size:18px">
                            <li>Distinguishability &ndash; are algorithm generated and HumanCam videos distinguishable?</li>
                            <li>HumanCam-Likeness &ndash; which algorithm generates videos that are closer to HumanCam videos?</li>
                            <li>Transferability &ndash; do semantic classifiers transfer between algorithm generated and HumanCam videos?</li>
                        </ul>
                        <div class="row">
                            <div class="col-md-6">
                                <img src="figures/distinguishability.png" class="img-responsive center-block" alt="Distinguishability" style="max-width=98%">
                            </div>
                            <div class="col-md-6">
                                <img src="figures/humancamlikeness.png" class="img-responsive center-block" alt="HumanCam-Likeness:" style="max-width=98%">
                            </div>
                        </div>
                        <li>HumanEdit-based Metrics &ndash; whether the algorithm controls the viewing direction similar to human viewers in the same 360° video</li>
                        <ul style="font-size:18px">
                            <li>Cosine &ndash; cosine similarity between the viewing directions of human viewer and algorithm output in the same 360° video</li>
                            <li>Overlap &ndash; field-of-view overlap of human viewer and algorithm output in the same 360° video</li>
                        </ul>
                    </ul>
                </div>
                <h3>Results</h3>
                <div class="row">
                    <div class="col-md-4">
                        <img src="figures/result_distinguishability.png" class="img-responsive center-block" alt="Distinguishability" style="max-width:98%">
                    </div>
                    <div class="col-md-4">
                        <img src="figures/result_humancamlikeness.png" class="img-responsive center-block" alt="HumanCam-Likeness" style="max-width:98%">
                    </div>
                    <div class="col-md-4">
                        <img src="figures/result_transferability.png" class="img-responsive center-block" alt="Transferability" style="max-width:98%">
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-4 col-md-offset-2">
                        <img src="figures/result_cosine.png" class="img-responsive center-block" alt="Cosine Similarity" style="max-width:98%">
                    </div>
                    <div class="col-md-4">
                        <img src="figures/result_overlap.png" class="img-responsive center-block" alt="FOV Overlap" style="max-width:98%">
                    </div>
                </div>
                [<a href="#">top</a>]
            </div>

            <div class="row" id="Video">
                <h2>Video Examples</h2>
                <hr class="single">
                <h3>AutoCam Outputs</h3>
                <div class="row">
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/u0arq11deq43w0e/3bflvCmcFaI-autocam.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/vns57f6ji4r42uk/6EOq6hIDX-4-autocam.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
                <div class="row" style="margin-top:21px">
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/mblr048sbe3ntzx/7g2k0eEQUaM-autocam.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/9ctiy10bejuo7i8/g6w6xkQeSHg-autocam.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>

                <h3>Comparison with Baseline</h3>
                <div class="row">
                    <div class="col-md-6">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/v8r9risg0hs3h1l/C7cxIamvRR4-baseline.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/4va5ts2pf9kmfrh/nT5ete4d8v0-baseline.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-12">
                        <p style="font-size:18px; margin-top:18px">
                            These two examples show why center and eye-level heuristics are reasonable baselines to compared with.
                        </p>
                            <ul style="font-size:18px">
                                <li>
                                Center &ndash; Videographers often hold the 360° camera in an orientation such that the center corresponds to some special directions,
                                e.g. the direction pointing to the videographer.
                                </li>
                                <li>
                                Eye-level &ndash; Most events appear near the horizon.
                                </li>
                            </ul>
                        <p style="font-size:18px;">
                            Nevertheless, they were unable to adapt to the content and often fail to achieve good framing.
                        </p>
                    </div>
                </div>

                <h3>Failure Cases</h3>
                <div class="row">
                    <div class="col-md-6">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/2slrgdgnff76vft/OyNHGJ3zIS8-autocam.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                        <p style="font-size:18px; margin-top:18px">
                            The first example shows two problems in the AutoCam algorithm:
                        </p>
                        <ul style="font-size:18px">
                            <li>The virtual camera has limited FOV and cannot capture the entire subject at once</li>
                            <li>The camera motion is restricted by the smooth camera motion constraint and can't turn to the subject promptly</li>
                        </ul>
                    </div>
                    <div class="col-md-6">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/q4vk5juinsl0rkv/67BUsqF14lY-autocam.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                        <p style="font-size:18px; margin-top:18px">
                            The second example shows that the capture-worthiness score does not encode the preference over different contents that look like HumanCam videos.
                        </p>
                    </div>
                </div>

                <h3>HumanEdit Interface</h3>
                <div class="row">
                    <div class="col-md-8 col-md-offset-2">
                        <div class="embed-responsive embed-responsive-16by9">
                            <video controls>
                                 <source src="https://www.dropbox.com/s/sgwwp1127g9xg14/humanedit_interface.mp4?raw=1" type="video/mp4">
                            </video>
                        </div>
                        <p style="font-size:18px; margin-top:18px">
                            Design highlights:
                        </p>
                        <ul style="font-size:18px">
                            <li>Display 360° video in equirectangular projection, so the editor can see all content at once</li>
                            <li>Expand the panoramic strip by 90° on both side to avoid discontinuous content</li>
                            <li>Human editor controls the virtual camera direction by the mouse location</li>
                            <li>Backproject the camera field-of-view to the 360° video</li>
                        </ul>
                    </div>
                </div>
                [<a href="#">top</a>]
            </div>

            <div class="row" id="publication">
                <h2>Publication</h2>
                <hr class="single">
                <ul style="font-size:18px">
                    <li>
                    Yu-Chuan Su, Dinesh Jayaraman, and Kristen Grauman,
                    "Pano2Vid: Automatic Cinematography for Watching 360° Videos,"
                    ACCV 2016 (Oral, Best Application Paper Award)<br>
                    [<a href="accv2016-0327su.pdf">pdf</a>]
                    [<a href="accv2016-0327su-supp.pdf">supp</a>]
                    [<a href="https://www.dropbox.com/s/4zlusopqb53czh0/pano2vid_accv16.pptx?dl=1">slide</a>]
                    [<a href="accv2016-0327su-poster.pdf">poster</a>]
                    [<a href="accv2016-0327su.bib">bib</a>]
                    [<a href="panoramic_videos.json">360° Videos</a>/<a href="humanCam.json">HumanCam</a>]
                    [<a href="human_edit.json">HumanEdit</a>]
                    [<a href="https://www.dropbox.com/s/s1g23kwldertd5b/humancam-c3d.pkl?dl=1">HumanCam C3D (fc6)</a>]
                    [<a href="https://github.com/sammy-su/Pano2Vid">Code</a>]
                    </li>
                </ul>
                [<a href="#">top</a>]
            </div>
        </div> <!-- /container -->

        <footer>
        </footer>

        <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
        <!-- Include all compiled plugins (below), or include individual files as needed -->
        <script src="../../js/bootstrap.min.js"></script>
        <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
         (i[r].q=i[r].q||[]).push(arguments)
         },i[r].l=1*new Date();a=s.createElement(o),
         m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
         })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-37193013-4', 'auto');
        ga('send', 'pageview');
        </script>
    </body>
</html>
