<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
        <title>Leaving Some Stones Unturned</title>

        <!-- Bootstrap -->
        <link href="css/bootstrap.min.css" rel="stylesheet">
        <link href="css/custom.css" type="text/css" rel="stylesheet">

        <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
            <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->
    </head>

    <body>

        <div class="container">
            <nav class="navbar navbar-default navbar-static-top">
                <div class="container-fluid">
                    <div class="navbar-header">
                        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
                            <span class="sr-only">Toggle navigation</span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </button>
                        <a class="navbar-brand" href="http://www.cs.utexas.edu/~grauman/research/pubs.html">
                            <span class="glyphicon glyphicon-home" aria-hidden="true"></span>
                        </a>
                    </div>

                    <div id="navbar" class="navbar-collapse collapse">
                        <ul class="nav navbar-nav">
                            <!--li class="active"><a href="http://www.cs.utexas.edu/~ycsu">Home</a></li-->
                            <li><a href="#approach">Approach</a></li>
                            <li><a href="#result">Result</a></li>
                            <li><a href="#examples">Examples</a></li>
                            <li><a href="#publication">Publication</a></li>
                        </ul>
                    </div><!--/.nav-collapse -->
                </div>
            </nav>

            <div class="row">
                <div class="row">
                    <h1>
                        <p class="text-center">
                            Leaving Some Stones Unturned:
                        </p>
                    </h1>
                    <h1>
                        <p class="text-center">
                            Dynamic Feature Prioritization for Activity Detection in Streaming Video
                        </p>
                    </h1>
                </div>
                <div class="row" style="margin-top:16px">
                    <p class="text-center" style="font-size:21px">
                        Yu-Chuan Su and Kristen Grauman <br>
                        The University of Texas at Austin
                    </p>
                </div>
                <h2>Abstract</h2>
                <p style="font-size:18px">
                    Current approaches for activity recognition often ignore constraints on computational resources:
                    1) they rely on extensive feature computation to obtain rich descriptors on all frames, and
                    2) they assume batch-mode access to the entire test video at once.
                    We propose a new <strong>active</strong> approach to activity recognition that prioritizes "what to compute when" in order to make timely predictions.
                    The main idea is to learn a policy that dynamically schedules the sequence of features to compute on selected frames of a given test video.
                    In contrast to traditional static feature selection,
                    our approach continually re-prioritizes computation based on the accumulated history of observations and accounts for the transience of those observations in ongoing video.
                    We develop variants to handle both the batch and streaming settings.
                    On two challenging datasets, our method provides significantly better accuracy than alternative techniques for a wide range of computational budgets.
                </p>
                [<a href="#">top</a>]
            </div>

            <div class="row" id="approach">
                <h2>Approach</h2>
                <hr class="single">
                <div class="row">
                    <img src="figures/approach.png" class="img-responsive center-block" alt="Approach figure" style="max-width:96%; width:960px;">
                </div>
                <p style="font-size:18px">
                    We formulate the problem as a Markov decision process (MDP) and learn the policy using reinforcement learning.
                    To apply reinforcement learning, we define the following components:
                </p>
                <ul style="font-size:18px">
                    <li>
                    <strong>State s<sub>k</sub></strong> <br>
                    captures the video content observed so far at the k-th step of the recognition episode. It is defined in terms of the history of extracted features and prior actions.
                    </li>
                    <li>
                    <strong>Action A={a<sub>m</sub>}</strong> <br>
                    a set of discrete actions the system can perform at each step in the episode, which lead to an update of the state.
                    An action either extracts information from the video or moves to the next frame in the stream.
                    </li>
                    <li>
                    <strong>Reward r<sub>k</sub>=R(s<sub>k</sub>, a<sup>(k)</sup>, s<sub>k+1</sub>)</strong>  <br>
                    the reward received when transits from state s<sub>k</sub> to s<sub>k+1</sub> after taking action a<sup>(k)</sup>.
                    We define the reward as the increase of the predicted probability of the correct activity class.
                    </li>
                </ul>
                <p style="font-size:18px">
                    We apply standard Q-learning with linear function approximation for the action-value function Q.
                    Please see the paper for details.
                </p>
                [<a href="#">top</a>]
            </div>

            <div class="row" id="result">
                <h2>Experiment Results</h2>
                <hr class="single">

                <p style="font-size:18px">
                We show the quantitative results under streaming and untrimmed detection setting with different video representations.
                We show the policies learned by the algorithm.
                Please refer to the paper for experiment details and more results.
                </p>

                <ul style="font-size:18px; margin-top:12px">
                    <li> Streaming + Bag-of-Object<br>
                    <div class="row">
                        <img src="figures/streaming.png" class="img-responsive center-block" alt="Bag-of-Object Streaming" style="max-width:96%; width:960px">
                    </div>
                    <p style="margin-top:12px">
                    Our method performs better under most object detector speed. See the left 2 figures.<br>
                    The advantage is most significant under low detector speed, or equivalently, low resource budget.<br>
                    </p>

                    <li style="margin-top:18px"> Streaming + CNN & IDT (UCF-101)<br>
                    <div class="row" style="margin-top:12px">
                        <img src="figures/cnn_streaming.png" class="img-responsive center-block" alt="CNN Streaming" style="max-width:96%; width:960px">
                    </div>
                    <p style="margin-top:12px">
                    Our method intelligently skips uninformative frames as the feature extraction speed increase. See the 1st figure.<br>
                    It reaches the ultimate performance by processing less than 40% of the frames. See figure 2&ndash;4.
                    </p>

                    <li style="margin-top:18px"> Untrimmed + Bag-of-Object<br>
                    <div class="row">
                        <img src="figures/untrimmed_fourcol.png" class="img-responsive center-block" alt="Untrimmed" style="max-width:96%; width:960px">
                    </div>
                    <p style="margin-top:12px">
                    Our method can achieve better accuracy (left-top) as well as reduce the computation cost (bot) under all object detector speed.<br>
                    Also, our method performs well on "early" detection, (measured by the AMOC curve, right-top). Please see the paper for explanation.
                    </p>

                    <li style="margin-top:18px"> Learned policy<br>
                    <div class="row">
                        <img src="figures/policy.png" class="img-responsive center-block" alt="Learned policy" style="max-width:92%; width:640px">
                    </div>
                </ul>

                [<a href="#">top</a>]
            </div>

            <div class="row" id="examples">
                <h2>Example Recognition Episodes</h2>
                <hr class="single">

                <p style="font-size:18px">
                We visualize the recognition episodes under streaming setting. These videos show how the policy operates in test time.
                </p>

                <p style="font-size:18px; margin-top:18px; margin-bottom:-4px"> &bull; ADL &mdash; Bag-of-Object</p>
                <div class="row">
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9 center-block" style="border:1px solid black; max-width:98%">
                             <video controls>
                                 <source src="http://vision.cs.utexas.edu/projects/leaving-some-stones-unturned/videos/example1.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9 center-block" style="border:1px solid black; max-width:98%">
                             <video controls>
                                 <source src="http://vision.cs.utexas.edu/projects/leaving-some-stones-unturned/videos/example2.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>

                <p style="font-size:18px; margin-top:18px; margin-bottom:-4px"> &bull; UCF-101 &mdash; Bag-of-Object</p>
                <div class="row">
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9 center-block" style="border:1px solid black; max-width:98%">
                             <video controls>
                                 <source src="http://vision.cs.utexas.edu/projects/leaving-some-stones-unturned/videos/example3.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9 center-block" style="border:1px solid black; max-width:98%">
                             <video controls>
                                 <source src="http://vision.cs.utexas.edu/projects/leaving-some-stones-unturned/videos/example4.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>

                <p style="font-size:18px; margin-top:18px; margin-bottom:-4px"> &bull; UCF-101 &mdash; CNN</p>
                <div class="row">
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9 center-block" style="border:1px solid black; max-width:98%">
                             <video controls>
                                 <source src="http://vision.cs.utexas.edu/projects/leaving-some-stones-unturned/videos/example5.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9 center-block" style="border:1px solid black; max-width:98%">
                             <video controls>
                                 <source src="http://vision.cs.utexas.edu/projects/leaving-some-stones-unturned/videos/example6.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-6" style="margin-top:12px">
                        <div class="embed-responsive embed-responsive-16by9 center-block" style="border:1px solid black; max-width:98%">
                             <video controls>
                                 <source src="http://vision.cs.utexas.edu/projects/leaving-some-stones-unturned/videos/example7.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <div class="col-md-6" style="margin-top:8px">
                        <div class="embed-responsive embed-responsive-16by9 center-block" style="border:1px solid black; max-width:98%">
                             <video controls>
                                 <source src="http://vision.cs.utexas.edu/projects/leaving-some-stones-unturned/videos/example8.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                </div>
                [<a href="#">top</a>]
            </div>
            <div class="row" id="publication">
                <h2>Publication</h2>
                <hr class="single">
                <ul style="font-size:18px">
                    <li>
                    Yu-Chuan Su and Kristen Grauman,
                    "Leaving Some Stones Unturned: Dynamic Feature Prioritization for Activity Detection in Streaming Video,"
                    ECCV 2016<br>
                    [<a href="eccv2016-1542su.pdf">pdf</a>]
                    [<a href="eccv2016-1542su-supp.pdf">supp</a>]
                    [<a href="dynamic_feature_prioritization_poster.pdf">poster</a>]
                    [<a href="eccv2016-1542su.bib">bibtex</a>]
                    </li>
                </ul>
                [<a href="#">top</a>]
            </div>
        </div> <!-- /container -->

        <footer>
        </footer>

        <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
        <!-- Include all compiled plugins (below), or include individual files as needed -->
        <script src="js/bootstrap.min.js"></script>
    </body>
</html>
